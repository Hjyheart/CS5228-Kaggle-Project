{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5228-2410 Final Project EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "*(from [Kaggle Project](https://www.kaggle.com/competitions/cs-5228-2410-final-project))*\n",
    "\n",
    "In this project, we look into the market for used cars in Singapore. Car ownership in Singapore is rather expensive which includes the very high prices for new and used cars (compared to many other countries). There are many stakeholders in this market. Buyers and sellers want to find good prices, so they need to understand what affects the value of a car. Online platforms facilitating the sale of used cars, on the other hand, want to maximize the number of sales/transactions.\n",
    "\n",
    "The goal of this task is to predict the resale price of a car based on its properties (e.g., make, model, mileage, age, power, etc). It is therefore first and foremost a regression task. These different types of information allow you to come up with features for training a regressor. It is part of the project for you to justify, derive and evaluate different features. Besides predicting the outcome in terms of a dollar value, other useful results include the importance of different attributes, the evaluation and comparison of different regression techniques, an error analysis and discussion about limitations and potential extensions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Steps\n",
    "1. Load dataset\n",
    "2. Initial inspection\n",
    "    - Basic information\n",
    "    - Summary stats\n",
    "3. Data quality check\n",
    "    - Missing values\n",
    "    - Identify duplicates\n",
    "    - Examine data types\n",
    "4. EDA\n",
    "    - Univariate analysis\n",
    "        - Numerical: histograms, boxplots\n",
    "        - Categorical: barplots, pie charts\n",
    "    - Bivariate analysis\n",
    "        - Scatterplots: price v numerical\n",
    "        - Boxplots: price v categorical\n",
    "    - Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from wordcloud import WordCloud\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1    Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2    Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of records: \",len(df_train))\n",
    "print(\"# of columns: \",len(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3    Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values\n",
    "def get_missing_info(df_train):\n",
    "    missing_values = df_train.isnull().sum()\n",
    "    missing_percentages = (missing_values / len(df_train) * 100).round(2)\n",
    "\n",
    "    missing_info = pd.DataFrame({\n",
    "        'missing_count': missing_values,\n",
    "        'missing_perc': missing_percentages\n",
    "    }).sort_values(by=\"missing_count\", ascending=False)\n",
    "\n",
    "    return missing_info\n",
    "\n",
    "missing_info = get_missing_info(df_train=df_train)\n",
    "print(\"\\n=== missing_count Analysis ===\")\n",
    "print(missing_info[missing_info['missing_count'] > 0].sort_values('missing_perc', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has significant missing data across several features:\n",
    "\n",
    "- 'indicative_price' is completely missing (100%)\n",
    "- 'opc_scheme' and 'original_reg_date' are missing for nearly all records (>98%)\n",
    "- 'lifespan' is missing for about 90% of the records\n",
    "- 'fuel_type' is missing for about 76% of the records\n",
    "- 'mileage' is missing for about 21% of the records\n",
    "- Several other fields have missing data ranging from 0.03% to 15.25%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Duplicate Records Analysis ===\")\n",
    "print(f\"Number of duplicate rows: {df_train.duplicated().sum()}\")\n",
    "print(f\"Number of duplicate listing_ids: {df_train['listing_id'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are no duplicate rows or listing_ids in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Since `indicative_price` is completely missing, drop column. \n",
    "- `listing_id` is not meaningful to the analysis as well. \n",
    "- Since `original_reg_date` is almost entirely missing, feature is not meaningful. Based on context, last `reg_date` may be more useful as it may be closely related to the COE price upon time of registration. COE has a heavy influence on car resale price.\n",
    "- `fuel_type` has many missing values but can potentially be obtained from `category`.\n",
    "- `lifespan` has many missing values but can potentially be inferred from the `title`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Textual Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df_train.select_dtypes(include=[\"object\"]).columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['title', 'description', 'category', 'features', 'accessories', 'opc_scheme', 'eco_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud for each text feature\n",
    "for feature in text_features:\n",
    "    text_data = ' '.join(df_train[feature].dropna().tolist())\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_data)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  \n",
    "    plt.title(f'Wordcloud â€“ {feature}')\n",
    "    plt.savefig(f'visualisations/wordcloud_{feature}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning & Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create binary variables from text features\n",
    "\n",
    "# Convert opc scheme to binary for further analysis\n",
    "df_train['opc_scheme'] = df_train['opc_scheme'].apply(lambda x: 1 if pd.notna(x) else 0)\n",
    "# Create column for parf v coe cars \n",
    "df_train['parf'] = df_train['category'].apply(lambda x: 1 if 'parf' in x else 0)\n",
    "# Create column for rare & exotic cars\n",
    "df_train['rare'] = df_train['category'].apply(lambda x: 1 if 'rare & exotic' in x else 0)\n",
    "# Create column for vintage cars\n",
    "df_train['vintage'] = df_train['category'].apply(lambda x: 1 if 'vintage' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['opc_scheme', 'parf', 'rare', 'vintage']\n",
    "for col in binary_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df_train[col].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Fix Missing Values (make) ===\")\n",
    "print(\"Missing values: \",df_train['make'].isna().sum())\n",
    "\n",
    "\n",
    "df_train['make']          = df_train['make'].str.upper()\n",
    "df_train['make']          = df_train['make'].str.replace(' ','').str.strip()\n",
    "df_train['title']         = df_train['title'].str.upper()\n",
    "\n",
    "make_list                   = [make for make in df_train['make'].unique().tolist() if type(make) == str]\n",
    "make_list.sort()\n",
    "print(\"Unique values: \")\n",
    "print(make_list[:20])\n",
    "print()\n",
    "\n",
    "df_train['make_temp']     = df_train['title'].str.split(' ').str[0]\n",
    "df_train['make_temp_similar']     = df_train.apply(lambda x: difflib.get_close_matches(x['make_temp'], make_list, n=1)[0], axis=1)\n",
    "\n",
    "df_train['make']          = df_train['make'].fillna(df_train['make_temp'])\n",
    "df_train                  = df_train.drop(columns = ['make_temp', 'make_temp_similar'])\n",
    "print(\"Missing values (after cleaning): \", df_train['make'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Fix Missing Values (manufactured) ===\")\n",
    "print(\"Missing values: \",df_train['manufactured'].isna().sum())\n",
    "\n",
    "df_train['original_reg_date']         = pd.to_datetime(df_train['original_reg_date'], format = \"%d-%b-%Y\")\n",
    "df_train['reg_date']                  = pd.to_datetime(df_train['reg_date'], format = \"%d-%b-%Y\")\n",
    "\n",
    "df_train['original_reg_date_temp']    = df_train['original_reg_date'].dt.year\n",
    "df_train['reg_date_temp']             = df_train['reg_date'].dt.year\n",
    "df_train['manufactured']              = df_train['manufactured'].fillna(df_train[['original_reg_date_temp','reg_date_temp']].min(axis=1))\n",
    "df_train['manufactured']              = df_train['manufactured'].astype(int).astype(str)\n",
    "df_train                              = df_train.drop(columns = ['original_reg_date_temp', 'reg_date_temp'])\n",
    "print(\"Missing values (after cleaning): \" ,df_train['manufactured'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Fix Missing Values (no_of_owners) ===\")\n",
    "print(\"Missing values: \",df_train['no_of_owners'].isna().sum())\n",
    "print(\"\\nSummary statistics: \", df_train['no_of_owners'].describe())\n",
    "df_train['no_of_owners'] = df_train['no_of_owners'].fillna(df_train['no_of_owners'].median())\n",
    "print(\"\\nMissing values (after cleaning): \" ,df_train['no_of_owners'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract fuel type from category\n",
    "fuel_keywords = {\n",
    "    'electric': 'electric',\n",
    "    'hybrid': 'petrol-electric'\n",
    "}\n",
    "\n",
    "def extract_fuel_type(category_text):\n",
    "    category_text = category_text.lower()  \n",
    "    for keyword, fuel_type in fuel_keywords.items():\n",
    "        if keyword in category_text:\n",
    "            return fuel_type\n",
    "    return None\n",
    "\n",
    "# Apply the function to the rows where fuel_type is missing\n",
    "df_train['fuel_type_category_fill'] = df_train['fuel_type']\n",
    "print(f\"Number of missing values for fuel_type (before): {df_train['fuel_type_category_fill'].isna().sum()}\")\n",
    "df_train.loc[df_train['fuel_type'].isna(), 'fuel_type_category_fill'] = df_train['category'].apply(extract_fuel_type)\n",
    "print(f\"Number of missing values for fuel_type (after): {df_train['fuel_type_category_fill'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping for fuel type from model make\n",
    "fuel_type_mapping = df_train.groupby(['make', 'model'])['fuel_type'].agg(lambda x: x.mode()[0] if not x.mode().empty else None).reset_index()\n",
    "fuel_type_dict = dict(zip(zip(fuel_type_mapping['make'], fuel_type_mapping['model']), fuel_type_mapping['fuel_type']))\n",
    "\n",
    "# Define a function to fill missing fuel types\n",
    "def fill_fuel_type(row, fuel_type_dict):\n",
    "    if pd.isna(row['fuel_type']):\n",
    "        return fuel_type_dict.get((row['make'], row['model']), None)\n",
    "    return row['fuel_type']\n",
    "\n",
    "# Apply the function to fill in missing values\n",
    "df_train['fuel_type_model_make_fill'] = df_train['fuel_type']\n",
    "print(f\"Number of missing values for fuel_type (before): {df_train['fuel_type_model_make_fill'].isna().sum()}\")\n",
    "df_train.loc[df_train['fuel_type'].isna(), 'fuel_type_model_make_fill']  = df_train.apply(fill_fuel_type, axis=1, fuel_type_dict=fuel_type_dict)\n",
    "print(f\"Number of missing values for fuel_type (after): {df_train['fuel_type_model_make_fill'].isna().sum()}\")\n",
    "\n",
    "df_train['fuel_type'] = df_train['fuel_type_model_make_fill']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coe end date from title\n",
    "df_train['coe_end'] = df_train['title'].str.extract(r'\\(COE TILL (\\d{2}/\\d{4})\\)')\n",
    "df_train['coe_end'] = pd.to_datetime(df_train['coe_end'], format='%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_info = get_missing_info(df_train=df_train)\n",
    "missing_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = df_train.select_dtypes(include=['int64', 'float64']).columns.drop(['listing_id', 'indicative_price'])\n",
    "\n",
    "print(\"\\n=== Numerical Features Analysis ===\")\n",
    "print(df_train[numerical_cols].describe())\n",
    "\n",
    "# Check for outliers using IQR method\n",
    "print(\"\\n=== Outlier Analysis (IQR Method) ===\")\n",
    "for col in numerical_cols:\n",
    "    Q1 = df_train[col].quantile(0.25)\n",
    "    Q3 = df_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df_train[(df_train[col] < (Q1 - 1.5 * IQR)) | (df_train[col] > (Q3 + 1.5 * IQR))][col]\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"Number of outliers: {len(outliers)}\")\n",
    "        print(f\"Percentage of outliers: {(len(outliers)/len(df_train)*100):.2f}%\")\n",
    "\n",
    "fig, axes = plt.subplots(len(numerical_cols), 2, figsize=(10, 2*len(numerical_cols)))\n",
    "\n",
    "for i, feature in enumerate(numerical_cols):\n",
    "    \n",
    "    # Histogram\n",
    "    sns.histplot(df_train[feature].dropna(), kde=True, ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f'Histogram of {feature}')\n",
    "    axes[i, 0].set_xlabel(feature)\n",
    "    \n",
    "    # Box plot\n",
    "    sns.boxplot(x=df_train[feature].dropna(), ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f'Box Plot of {feature}')\n",
    "    axes[i, 1].set_xlabel(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visualisations/distribution_numerical.png\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plot correlation matrix of numerical features\"\"\"\n",
    "corr = df_train[numerical_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.savefig(\"visualisations/correlation_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strongest correlations with price**\n",
    "- dereg_value (0.91)\n",
    "- arf (0.89)\n",
    "- omv (0.82)\n",
    "- depreciation (0.81)\n",
    "- power (0.70)\n",
    "\n",
    "Focus on these features for initial modelling effort.\n",
    "\n",
    "\n",
    "**Moderate correlations with price**\n",
    "- road_tax (0.52)\n",
    "- engine_cap (0.44)\n",
    "- coe (0.35)\n",
    "- mileage (-0.39)\n",
    "- rare (0.60)\n",
    "\n",
    "**Low correlation with price**\n",
    "- manufactured (0.20)\n",
    "- curb_weight (0.15)\n",
    "- no_of_owners (-0.08)\n",
    "\n",
    "**Strong correlations between features**\n",
    "\n",
    "- omv and arf (0.94)\n",
    "- engine_cap and road_tax (0.94)\n",
    "- power and engine_cap (0.86)\n",
    "\n",
    "Potential multicollinearity which may impact some models (tree-based models are less sensitive). Choose most relevant features or employ dimensionality reduction methods like PCA.\n",
    "Feature engineering to create interaction terms between strongly related features (e.g. power * engine cap)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_corr_price = ['dereg_value', 'arf', 'omv', 'depreciation', 'power']\n",
    "moderate_corr_price = ['road_tax', 'engine_cap', 'coe', 'mileage', 'rare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_and_binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.pairplot(df_train, vars=strong_corr_price + ['price'], hue='parf')\n",
    "plt.title('Features with strong corr with Price Pairplot (by parf)')\n",
    "plt.savefig(\"visualisations/pairplot_strong_corr_by_parf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.pairplot(df_train, vars=strong_corr_price+['price'], hue='rare')\n",
    "plt.title('Features with strong corr with Price Pairplot (by rare)')\n",
    "plt.savefig(\"visualisations/pairplot_strong_corr_by_rare.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.pairplot(df_train, vars=moderate_corr_price + ['price'], hue='parf')\n",
    "plt.title('Features with strong corr with Price Pairplot (by parf)')\n",
    "plt.savefig(\"visualisations/pairplot_mod_corr_by_parf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.pairplot(df_train, vars=moderate_corr_price+['price'], hue='rare')\n",
    "plt.title('Features with strong corr with Price Pairplot (by rare)')\n",
    "plt.savefig(\"visualisations/pairplot_mod_corr_by_rare.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"\\n=== Categorical Features Analysis ===\")\n",
    "for col in categorical_cols:\n",
    "    unique_values = df_train[col].nunique()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Number of unique values: {unique_values}\")\n",
    "    if unique_values < 10:  # Only show value counts for columns with few unique values\n",
    "        print(df_train[col].value_counts().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- eco_category has the same value for all rows. Drop column.\n",
    "- opc_scheme has 3 unique values. Present value seem to indicate that the car is under OPC scheme. Convert to binary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Analysis (with added binary features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.columns)\n",
    "print(categorical_cols)\n",
    "print(binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_and_binary_cols = list(categorical_cols) + binary_columns\n",
    "categorical_and_binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_UNIQUE_VALUES = 30\n",
    "for feature in categorical_and_binary_cols:\n",
    "    if len(df_train[feature].value_counts()) < MAX_UNIQUE_VALUES:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.countplot(y=feature, data=df_train, order=df_train[feature].value_counts().index)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'visualisations/distribution_categorical_{feature}.png')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        # Relationship with price\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.boxplot(x=feature, y='price', data=df_train)\n",
    "        plt.title(f'{feature} vs Price')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'visualisations/price_vs_{feature}.png')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Type of vehicle:\n",
    "    - SUVs, luxury sedans, and sports cars are the most common vehicle types in the dataset. - SUVs are highly represented, with relatively lower price variability compared to luxury sedans and sports cars.\n",
    "    - Truck, station wagon, and bus/mini bus have lower counts, indicating that these vehicle types are less represented in this dataset, possibly niche categories. Generally lower median prices.\n",
    "    - Luxury sedans and sports cars show the highest resale prices, as expected given the premium nature of these vehicles. There are several outliers in these categories, indicating that some cars are priced significantly higher than the rest.\n",
    "    - SUVs have a relatively wide price range, with a number of outliers in the upper range, possibly high-end or luxury SUVs. \n",
    "    \n",
    "- Tranmission type:\n",
    "    - The majority of vehicles in the dataset have automatic transmission.\n",
    "    - Manual transmission vehicles tend to have a lower price range overall compared to automatics. However, there are still some outliers with higher prices, which may correspond to specific models that are rarer or in high demand among enthusiasts (e.g., sports cars with manual transmission).\n",
    "\n",
    "- Fuel type:\n",
    "    - The most common fuel type is diesel, followed by petrol-electric and petrol. This suggests a significant preference for diesel vehicles in the dataset.\n",
    "    - Electric vehicles are less common, while diesel-electric vehicles have the lowest count among the listed fuel types.\n",
    "    - Petrol-electric vehicles also show a significant range in pricing, with some outliers that could represent premium models. This suggests that hybrid vehicles are valued well in the resale market.\n",
    "    - Electric vehicles have a narrower price range compared to diesel and petrol-electric, suggesting that the market for used electric vehicles may not be as established yet, potentially affecting their resale value.\n",
    "    - Note: Many missing values for this feature\n",
    "- opc_scheme:\n",
    "    - Since the feature is highly imbalanced, box plot is not very useful\n",
    "- parf:\n",
    "    - parf cars have a slightly higher range compared to coe cars. \n",
    "- rare:\n",
    "    - Rare cars can command much higher resale prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_features = ['original_reg_date','reg_date', 'lifespan', 'coe_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Date Fields Analysis ===\")\n",
    "for col in date_features:\n",
    "\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"Unique values sample: {df_train[col].unique()[:5]}\")\n",
    "    # Check for invalid dates\n",
    "    try:\n",
    "        df_train[col] = pd.to_datetime(df_train[col])\n",
    "        print(\"Min date:\", df_train[col].min())\n",
    "        print(\"Max date:\", df_train[col].max())\n",
    "    except:\n",
    "        print(\"Error converting to datetime - possible invalid date formats\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(df_train['price'])\n",
    "plt.title('Boxplot of Price to detect outliers')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train['price']==max(df_train['price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5228",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
